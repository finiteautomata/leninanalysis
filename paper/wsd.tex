Word sense disambiguation involves the association of a given word in a text or discourse with a definition or meaning.

Our approach for WSD was a classical Lesk\cite{LESK} implementation that uses wordnet as a definition source with some tweaks.\\
Basically Lesk is based on the idea that words that coâ€“occur in a sentence are being used to refer to the same topic. \\
The Lesk algorithm takes the word definition or gloss that we want to disambiguate and it compares it gloss against the glosses of the other words in the context, then a word is assigned that sense whose gloss shares the largest number of words in common with the glosses of the other words.\\
This algorithm suffers the problem that relies on the word definition and definitions usually uses as less words as possible. Not only that sometimes two different words, but related ones, uses no words in common in their definitions. \\
As we use the nltk wordnet we immediately notice an improvement using the rich set of relationships that Wordnet gives to us, so we added to our Lesk implementation word stems, hypernyms, hyponyms.
For the problem of short word description we modified the algorithm to use the definition of the word to disambiguate and to compare it against the context words directly.
Finally our algorithm chooses the best synset from wordnet based on the context words. \\
We had choosen the whole text as context for all runs.
