%% PNAStwoS.tex
%% Sample file to use for PNAS articles prepared in LaTeX
%% For two column PNAS articles
%% Version: Apr 15, 2008 
 

%% BASIC CLASS FILE
\documentclass{pnastwo}

%% ADDITIONAL OPTIONAL STYLE FILES
%\usepackage[dvips]{graphicx}
%\usepackage{pnastwof}
\usepackage{amssymb,amsfonts,amsmath}
\usepackage[utf8]{inputenc}
\usepackage[dvips]{graphicx}
\usepackage{bookmark}
\usepackage{color}
\usepackage{array}
\usepackage{setspace}
\usepackage{longtable}
\usepackage[hmargin=2cm,vmargin=2.5cm]{geometry}
\usepackage{booktabs}
\usepackage{colortbl}
\newcolumntype{L}[1]{>{\raggedright\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
\newcommand{\myrowcolour}{\rowcolor[gray]{0.925}}
  \newcommand{\cheading}[2]{\textbf{#1\hfill #2}}

\newcommand\dq[1]{\textquotedblleft #1\textquotedblright}
\newcommand\sq[1]{\textquoteleft #1\textquoteright}
\newcommand*{\allref}[1]{\ref{#1} \nameref{#1}}

%% OPTIONAL MACRO DEFINITIONS
\def\s{\sigma}


%%%%%%%%%%%%
%% For PNAS Only:
%\url{www.pnas.org/cgi/doi/10.1073/pnas.0709640104}
\copyrightyear{2008}
\issuedate{Issue Date}
\volume{Volume}
\issuenumber{Issue Number}
%\setcounter{page}{2687} %Set page number here if desired
%%%%%%%%%%%%

\begin{document}

\title{A word-sense representation for documents based on information value and word sense disambiguation}

\author{Leonardo Lazzaro\affil{1}{Universidad de Buenos Aires, Buenos Aires, Argentina},
Julián Peller\affil{1}{Universidad de Buenos Aires, Buenos Aires, Argentina},
Juan Manuel Pérez\affil{1}{Universidad de Buenos Aires, Buenos Aires, Argentina}
}


\maketitle

\begin{article}
\begin{abstract}
In this project we analyzed some Lenin works in order to identify the presence of some topics of his biography. To achieve this, we defined and implemented a simple metric distance between a word-sense and a document and confronted this metric using a evaluation set of word-senses against a reduced set of  documents with well known topics. During this work, we generated an indexed database of Lenin's complete works from a web site\cite{LENIN} and we applied a series of syntactic, semantic and lexicographic tools in order to model the similarity between a document and a word-sense. We applied information value\cite{DARWIN} and a simple algorithm of word sense disambiguation\cite{LESK} based on Wordnet\cite{WORDNET} in order to generate the \emph{top senses} (or principal senses) of a document. Finally, we compare them against some semantic senses of interest (for example: revolution, war, philosophy, etc). 
\end{abstract}

\keywords{information value | word sense disambiguation | natural language processing | information retrieval | polysemy }

%\abbreviations{NLP}

\section{Introduction}

\dropcap{I}n this article we propose a simple distance metric between a word-sense and a text document using different well known tools from natural language processing. To achieve this, we extract a hierarchy of the most representative words of a document (\textit{top words}) using the concept of \textit{information value}, a statistical linguistic model based on Shannon's information theory and proposed by Zanette et al. in\cite{DARWIN}. Briefly, information value allows us to represent a document like a ranked set of words. 

But this weighted set of top words has the problem of polysemy, typical in the field of nlp. Polysemy occurs when a term has more than one sense or meaning, for example: the term 'bank' can refer to a financial institution or to a land formation, thus, it is polysemic. In order to resolve this limitation, we implement a basic algorithm of word-sense disambiguation based on wordnet's synsets and we apply it over the top words, using as disambiguation context the whole document. We obtain, then, the \textit{top senses} of a document, this is, a ranked set of wordnet synsets that work like a representation of the given document.

Finally, we utilize different wordnet predefined metrics of similarity between synsets to define our own similarities between the top-sense representation of a document and any given word-sense (wordnet synset). In order to evaluate the behaviour of this metrics, we test the distances of the top-senses representation of some well known documents with very specific topics against a bounded set of relevant evaluation word-senses. 


\section{Method}
\subsection{Text Corpus}

We selected some starred works from Lenin from the ``Marxists Internet Archive''\cite{LENIN}. Those works are very different in topic, some of them being strictly phylosophical essays (such as ``Materialism and Empiriocriticism'') and other being more political, such as ``State and Revolution'', and finally an economic essay called ``Imperialism, the highest stage of capitalism''. 

\begin{itemize}
  \item What is to be done(1901)
  \item The Agrarian Programme of Social-Democracy in the First Russian Revolution, 1905-1907 (1907)
  \item Materialism and Empiriocriticism (1908)
  \item Imperialism, the highest stage of capitalism (1916)
  \item State and Revolution (1917)
\end{itemize}


For this purpose, we developed a web crawler to fetch the works from the \cite{LENIN}, but ended up using only these works.

%*Números (obras totales obtenidas, promedio tokens)
\subsection{Semantic Analysis}
\medskip
\subsubsection{Information value}

The information value of a word for a given text is defined and tested by Zanette \textit{et al.} in \cite{DARWIN} and \cite{ENTROPIC}.
It is a real value that quantifies how much information a word carries according to the text. Let $T$ be a 
text, and $T'$ a random shuffled version of $T$, and $w$ a word appearing in $T$. 
By $S_T(w)$ we denote the Shannon Entropy of $w$ with respect to $T$ (See appendix for more info). 

The information value of $w$ in $T$ is 

\begin{equation}
  IV_T(w) = f_w* | S_T(w) - S_{T'}(w) | 
\end{equation}

where $f_w$ is the frequency of appearance of $w$ in $T$. This value captures, in some way, whether a word
has a distribution in text that is not exactly uniform; an order of the word in the text that brings some sense to it. 


Ordering the words by their information value results in a list of the text's most representative words. In the context of our research, we call the first $n$ words of a text -with $n$ fixed-, ordered by it's information value, the \textit{top words} of the document. 

That's it, if we have all the words sorted as $w_1, w_2, \ldots , w_M$ such that $ i \leq j \Rightarrow IV_{T}(w_i) >= IV_{T}(w_j)$, then, the $n$ top words are $w_1, w_2, \ldots w_n$

\subsubsection{Wordnet synsets \& similarities}

Having the \textit{top-words} representation of a document, we were interested in measuring the distance or similarity of that text to different words. In order to address this problem we used different similarity functions defined over wordnet in the python's library nltk\footnote{\url{http://www.nltk.org/}}. Wordnet is a lexical resource known as thesaurus, i. e, a data base of terms grouped as sets of synonyms (synsets), each of which have a definition and different semantic relations with others synsets (for example: hypernymy, hyponymy, meronymy, etc). The similarity functions are defined over this network of semantic relations.

This functions aren' t defined over words but over synsets. A synset, briefly, is an abstract notion of sense, meaning or concept that is independent from it's linguistic formulation or spelling. Using synsets instead of words, the wordnet thesaurus solves two problems of ambiguity limited to the linguistic domain: polisemy and synonymy. Polisemy occurs when a unique term may refer to more than one concept (for example, bank may refer to a financial institution or to a land formation. In the other hand, synonymy occurs when different terms refer to the same concept (for example \sq{car} and \sq{automobile} refers, both, to the same concept).

The similarities defined in the nltk-api are the following: Path similarity, Leacock-Chodorow similarity, Wu-Palmer similarity, Resnik similarity, Jiang-Conrath similarity and Lin similarity. The former three are analytical, this is, their calculus is based only in the semantic relations of the thesaurus, meanwhile, the last three are analytical but also use statistics from a corpus.\cite{BUDANITSKY}\cite{BUDANITSKY_2}. In this project, we present the results measured with path similarity because the idea is to present a proof of concept of a representation for documents (and not a `productive' one). This similarity represents the distance between two nodes in Wordnet based on the shortest path that connects the senses in the is-a (hypernym/hypnoym) taxonomy.


\subsubsection{Word sense disambiguation}
\input{wsd}
\subsubsection{Top-sense definition}

In a first approach, we pretend to measure the distance between a document (represented by it's \textit{top words}) and different words. To address this problem using the wordnet distances between synsets described before, we modeled the notion of \sq{word} as the sum of all its synsets. The results were pretty demotivating, so we refocused our energy in order to define our problem in the space of word-senses (and no more in the space of words). 

Using the WSD algorithm described in the previous section, we defined the notion of \textit{top senses} of a document as the word-senses resulting from the disambiguation of the \textit{top words} of the documents obtained with Zannete's information value approach.

Given $w_1, \ldots, w_M$, words of $T$ sorted by information value, and suppose that $w_{i_1}, w_{i_2}, \ldots, w_{i_n}$ are the $n$ first words  such that disambiguation for each $w_{i_j}$ is feasible. Then, the top senses for $T$ are
\begin{equation}
  WSD(w_1), WSD(w_2), \ldots, WSD(w_n)
\end{equation}

\subsubsection{Word-senses evaluation set}

Based on this definition, we evaluate the resultant \textit{top senses} of some texts and then check the results of the different similarities with well known concepts in the next sections.

The selected concepts are shown in the table below. We can distinguish three subsets in this selection: concepts related to practical situations like geopolitics and state management (like `war', `strategy', `money'), concepts more related to the theoretical world (like  `philosophy', `idealism', `theory') and finally, concepts not related to Lenin's works (like `sugar', `car', `television\_receiver'). The motivation behind the selection of the two first groups is to check some easy hipotheses (such as ``State and Revolution'' talks a lot about ``state'' and ``revolution'', the motivation behind the third group is to check our methods looking for false positives, i.e., a high ranking in the metrics for a concept assumed not related to the works. The distinction between the two first groups and the third in pretty taxative, while the distinction between first and second group is more smooth.

Finally, we define the similarity between a document and a word-sense as follows:

\begin{equation}
  similarity(w, T) = max(path\_similarity(w, top\_senses_n(T)))
\end{equation}


\input{handpicked_table}
\section{Results}
This section is divided in two: first, we present the \textit{top senses} of the documents listed in ``Text corpus''; second, we present the similarities between the documents and the word-senses evaluation set.

%\subsubsection{Top senses for selected works}
\input{results}


ASDQWEQWEQWEQWEQ FILL THIS WITH SOME TEXT ASDQWEQWEQWEQWEQ FILL THIS WITH SOME TEXT ASDQWEQWEQWEQWEQ FILL THIS WITH SOME TEXT ASDQWEQWEQWEQWEQ FILL THIS WITH SOME TEXT ASDQWEQWEQWEQWEQ FILL THIS WITH SOME TEXT ASDQWEQWEQWEQWEQ FILL THIS WITH SOME TEXT ASDQWEQWEQWEQWEQ FILL THIS WITH SOME TEXT ASDQWEQWEQWEQWEQ FILL THIS WITH SOME TEXT ASDQWEQWEQWEQWEQ FILL THIS WITH SOME TEXT  

%\subsubsection{Similarities with chosen concepts}
\input{results_sim_tables}

\newpage

\subsubsection{Observations}

\section{Discussion}


\subsection{Top senses of a text}
The method used here, as explained before, was intended just to present the model of creating a list of top senses out of a list of top words. In spite of being quite elemental, the method worked fairly well with most texts, having some expected problems.

The main issues concern about Lesk Algorithm's flaws. One of these is the sensitivity of the context, for which the appearance or not of a single word in the gloss/context can radically change the selected sense for the word. Moreover, we strongly depend on glosses defined by Wordnet, which tend to be short.

Another issue is Wordnet itself. While it has overwhelming information for nouns and their relationships, the resources for verbs and adjectives are not as extensive. This fact was a problem not only for the construction of the glosses for Lesk, but also for measuring distances between synsets and works.

\subsection{Wordnet's synset distances}

As in the WSD problem, we also here just present a simple model to the problem of measuring a distance between a document and a -synset. The path similarity is a very simple similarity measure, which is based only in the distance between two synsets. Other 

For ``State and Revolution'', the distance worked as expected, matching with a high similarity those concepts highly related to the topics of the text, and putting down those unrelated. However, we must note that many synsets were extremely close of ``law.n.04'', which is a problem carried by a wrong disambiguation (the definition for it has to do with ``natural laws'', nothing to do with the text).

In ``Imperialism ... '', we suffered the appearance of a very general sense (universe.n.01) which made a nonrelated sense as hair to appear second in the ranking. Also, a very characteristic concept of the  as \textbf{capitalism} appears unrelated, because it is not very close (in the hypernyms/hyponyms taxonomy) to the top senses of this work. ``Materialism ... '' had the same problem but the other way around: \textbf{revolution} was just very close to \textbf{experience}, but had nothing to do with the text in general.

Many of these problems come from the fact that path similarity is not a good measure of semantic similarity. Of course, two senses which have a high path similarity are similar (they are very close in terms of hypernyms/hyponyms), but the other way round is not valid. For instance, meronimy is not taken into account in this metric.
 
Notice that, in order to use the path similarity, we had to select only noun senses for the top words. This is because verbs, adjectives and nouns are in different taxonomies in Wordnet, and hence are not comparable with this similarity. 





\section{Conclussion \& Future work}

The original scope of this investigation was the definition of a measure of distance between the works of a whole year and a concept; so we could measure whether the literary production of Lenin in some year was close to ``revolution'', ``theory'', etc.  With this purpose, we defined the \textbf{top senses} of a text, and measured the distance between them and other senses in a topological way.

Although the final results were not the expected, some tools we developed in our way proved to be promising. The hybrid method for extracting top senses of the text based in entropy analisis plus sense disambiguation worked in an acceptable fashion, with lot of room for improvement by using better WSD algorithms. In the other hand, the topological representation of a text as a set of senses has yet to experimented with better semantic similarity functions than the one used here. 



\input{apendices}
% *SynsetAnalyzer
%   *Synset
%   *path, lch, wup
% *judge_word
% *judge_doc
% *judge_year
% Dado un conjunto de palabras, definimos la distancia de una palabra a este conjunto como 
% 




\section{Acknowledgments}
Thanks to \hyperlink{https://www.marxists.org}{Marxists Internet Archive} for helping us retrieve the Lenin's complete works.


\begin{thebibliography}{10}
\bibitem{LENIN}
Marxists Internet Archive (\url{http://www.marxists.org})
\bibitem{DARWIN}
M.A. Montemurro \& D. H. Zanette, 2009, {\em The statistics of meaning: Darwin, Gibbon and Moby Dick}, Significance, Dec. 2009, 165-169.
\bibitem{ENTROPIC}
M.A. Montemurro \& D. H. Zanette, 2001, {\em Entropic analysis of the role of words in literary texts}, Adv. Complex Systems Vol. 5, September 27th 2001
\bibitem{MAS-ZANETTE}
M.A. Montemurro \& D. H. Zanette, 2010, {\em Towards the quantification of the semantic information encoded in written language}, Adv. Complex Systems Vol. 13.
\bibitem{WORDNET}
George A. Miller, 1995, {\em WordNet: A Lexical Database for English }, COMMUNICATIONS OF THE ACM November 1995/Vol. 38, No. 11
\bibitem{LESK}
M. Lesk., 1986, {\em Automatic sense disambiguation using machine readable dictionaries: How to tell a pine cone from a ice cream cone}. In Proceedings of SIGDOC ’86.
\bibitem{BUDANITSKY}
Budanitsky \& Hirst, 2004, {\em Evaluating WordNet-based Measures of Lexical Semantic Relatedness}
%\url{http://aclweb.org/anthology//J/J06/J06-1003.pdf}
\bibitem{BUDANITSKY_2}
Budanitsky \& Hirst, 2001, {\em Semantic distance in WordNet: An experimental, application-oriented evaluation of five measures}
%\bibitem{SLEZAK}
%C. Diuk, D. Slezak et al., 2013, {\em A quantitative philology of introspection}, Frontiers in Integrative Neuroscience Vol. 8
\end{thebibliography}


\end{article}
\end{document}





